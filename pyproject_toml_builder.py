"""Module to build `pyproject.toml` sections for use by `setup.py`/`setuptools`.

Used in CI/CD, used by GH Action.
"""

import argparse
import dataclasses
import itertools
import logging
import os
import re
from pathlib import Path
from typing import Any, cast

import requests
import tomlkit
from tomlkit import TOMLDocument, array
from wipac_dev_tools import (
    argparse_tools,
    logging_tools,
    semver_parser_tools,
    strtobool,
)

from find_packages import iterate_dirnames

BUILDER_SECTION_NAME = "wipac:cicd_setup_builder"
GENERATED_STR = f"generated by {BUILDER_SECTION_NAME}"
REAMDE_BADGES_START_DELIMITER = "<!--- Top of README Badges (automated) --->"
REAMDE_BADGES_END_DELIMITER = "<!--- End of README Badges (automated) --->"

LOGGER = logging.getLogger("setup-builder")


PythonMinMax = tuple[tuple[int, int], tuple[int, int]]


class GitHubAPI:
    """Relay info from the GitHub API."""

    def __init__(self, github_full_repo: str, oauth_token: str) -> None:
        self.url = f"https://github.com/{github_full_repo}"

        _headers = {"authorization": f"Bearer {oauth_token}"}
        _req = requests.get(
            f"https://api.github.com/repos/{github_full_repo}",
            headers=_headers,
        )
        _req.raise_for_status()
        _json = _req.json()
        self.default_branch = cast(str, _json["default_branch"])  # main/master/etc.
        self.description = cast(str, _json["description"])


@dataclasses.dataclass
class GHAInput:
    """The inputs passed from the client GitHub Action."""

    # REQUIRED
    python_min: tuple[int, int]

    # OPTIONAL (python)
    python_max: tuple[int, int] = dataclasses.field(
        default_factory=semver_parser_tools.get_latest_py3_release  # called only if no val
    )
    # OPTIONAL (packaging)
    package_dirs: list[str] = dataclasses.field(default_factory=list)
    exclude_dirs: list[str] = dataclasses.field(
        default_factory=lambda: [  # cannot use mutable type
            "test",
            "tests",
            "doc",
            "docs",
            "resource",
            "resources",
            "example",
            "examples",
        ]
    )
    # OPTIONAL (releases)
    pypi_name: str = ""
    # OPTIONAL (meta)
    keywords: list[str] = dataclasses.field(default_factory=list)
    author: str = ""
    author_email: str = ""

    # OPTIONAL (license)
    license_spdx_id: str = ""
    license_file: str = ""

    auto_mypy_option: bool = False

    def __post_init__(self) -> None:
        # pypi-related metadata
        if self.pypi_name:
            if not self.keywords or not self.author or not self.author_email:
                raise Exception(
                    "'keywords', 'author', and 'author_email' must be provided when "
                    "'pypi_name' is `True`"
                )

        # validate python min/max
        for major, attr_name in [
            (self.python_min[0], "python_min"),
            (self.python_max[0], "python_max"),
        ]:
            if major < 3:
                raise Exception(
                    f"Python-release automation ('{attr_name}') does not work for python <3."
                )
            elif major >= 4:
                raise Exception(
                    f"Python-release automation ('{attr_name}') does not work for python 4+."
                )

    def get_requires_python(self) -> str:
        """Get a `[project]/python_requires` string from `self.python_range`.

        Ex: "">=3.6, <3.10" (cannot do "<=3.9" because 3.9.1 > 3.9)
        """
        return f">={self.python_min[0]}.{self.python_min[1]}, <{self.python_max[0]}.{self.python_max[1] + 1}"

    def python_classifiers(self) -> list[str]:
        """Get auto-detected `Programming Language :: Python :: *` list.

        NOTE: Will not work after the '3.* -> 4.0'-transition.
        """
        return [
            f"Programming Language :: Python :: 3.{r}"
            for r in range(self.python_min[1], self.python_max[1] + 1)
        ]


class FromFiles:
    """Get things that require reading files."""

    def __init__(
        self,
        root: Path,
        gha_input: GHAInput,
    ) -> None:
        if not os.path.exists(root):
            raise NotADirectoryError(root)
        self.gha_input = gha_input
        self.root = root.resolve()
        self._pkg_paths = self._get_package_paths(self.gha_input.exclude_dirs)
        self.packages = [p.name for p in self._pkg_paths]
        self.readme_path = self._get_readme_path()

        self.check_no_version_dunders()  # do now so we don't forget to

    def _get_package_paths(self, dirs_exclude: list[str]) -> list[Path]:
        """Find the package path(s)."""

        if not (available_pkgs := list(iterate_dirnames(self.root, dirs_exclude))):
            raise Exception(
                f"No package found in '{self.root}'. Are you missing an __init__.py?"
            )

        # check the pyproject.toml: package_dirs
        if self.gha_input.package_dirs:
            if not_ins := [
                p for p in self.gha_input.package_dirs if p not in available_pkgs
            ]:
                if len(not_ins) == 1:
                    raise Exception(
                        f"Package directory not found: "
                        f"{not_ins[0]} (defined in pyproject.toml). "
                        f"Is the directory missing an __init__.py?"
                    )
                raise Exception(
                    f"Package directories not found: "
                    f"{', '.join(not_ins)} (defined in pyproject.toml). "
                    f"Are the directories missing __init__.py files?"
                )

            return [self.root / p for p in self.gha_input.package_dirs]
        # use the auto-detected package (if there's ONE)
        else:
            if len(available_pkgs) > 1:
                raise Exception(
                    f"More than one package found in '{self.root}': {', '.join(available_pkgs)}. "
                    f"Either "
                    f"[1] list *all* your desired packages in your pyproject.toml's 'package_dirs', "
                    f"[2] remove the extra __init__.py file(s), "
                    f"or [3] list which packages to ignore in your GitHub Action step's 'with.exclude-dirs'."
                )
            return [self.root / available_pkgs[0]]

    def check_no_version_dunders(self) -> None:
        """Check that no modules' __init__.py define a __version__ attribute."""
        for pkg in self._pkg_paths:
            with open(pkg / "__init__.py") as f:
                for line in f:
                    if "__version__" in line and "=" in line:
                        raise Exception(
                            f"Module ({pkg.name}) '__init__.py' must not define '__version__'."
                        )

    def _get_readme_path(self) -> Path:
        """Return the 'README' file and its extension."""
        for fname in self.root.iterdir():
            if fname.stem == "README":
                return Path(fname)
        raise FileNotFoundError(f"No README file found in '{self.root}'")


class READMEMarkdownManager:
    """Add some automation to README.md."""

    def __init__(
        self,
        ffile: FromFiles,
        github_full_repo: str,
        gha_input: GHAInput,
        gh_api: GitHubAPI,
    ) -> None:
        self.ffile = ffile
        self.github_full_repo = github_full_repo
        self.bsec = gha_input
        self.gh_api = gh_api
        with open(ffile.readme_path) as f:
            lines_to_keep = []
            in_badges = False
            for line in f.readlines():
                if line.strip() == REAMDE_BADGES_START_DELIMITER:
                    in_badges = True
                    continue
                if line.strip() == REAMDE_BADGES_END_DELIMITER:
                    in_badges = False
                    continue
                if in_badges:
                    continue
                lines_to_keep.append(line)
        self.lines = self.badges_lines() + lines_to_keep

    @property
    def readme_path(self) -> Path:
        """Get the README file path."""
        return self.ffile.readme_path

    def badges_lines(self) -> list[str]:
        """Create and return the lines used to append to a README.md containing various linked-badges."""
        badges_line = ""

        # PyPI badge
        if self.bsec.pypi_name:
            badges_line += f"[![PyPI](https://img.shields.io/pypi/v/{self.bsec.pypi_name})](https://pypi.org/project/{self.bsec.pypi_name}/) "

        # GitHub Release badge
        badges_line += f"[![GitHub release (latest by date including pre-releases)](https://img.shields.io/github/v/release/{self.github_full_repo}?include_prereleases)]({self.gh_api.url}/) "

        # Python versions
        if self.bsec.pypi_name:
            badges_line += f"[![Versions](https://img.shields.io/pypi/pyversions/{self.bsec.pypi_name}.svg)](https://pypi.org/project/{self.bsec.pypi_name}) "

        # PYPI License badge
        if self.bsec.pypi_name:
            badges_line += f"[![PyPI - License](https://img.shields.io/pypi/l/{self.bsec.pypi_name})]({self.gh_api.url}/blob/{self.gh_api.default_branch}/LICENSE) "

        # Other GitHub badges
        badges_line += (
            f"[![GitHub issues](https://img.shields.io/github/issues/{self.github_full_repo})]({self.gh_api.url}/issues?q=is%3Aissue+sort%3Aupdated-desc+is%3Aopen) "
            f"[![GitHub pull requests](https://img.shields.io/github/issues-pr/{self.github_full_repo})]({self.gh_api.url}/pulls?q=is%3Apr+sort%3Aupdated-desc+is%3Aopen) "
        )

        return [
            REAMDE_BADGES_START_DELIMITER,
            "\n",
            badges_line.strip(),  # remove trailing whitespace
            "\n",
            REAMDE_BADGES_END_DELIMITER,
            "\n",  # only one newline here, otherwise we get an infinite commit-loop
        ]


TOMLDocumentIsh = Any  # TOMLDocument & mypy aren't friendly, so it's either this or a million 'ignore' comments


class PyProjectTomlBuilder:
    """Build out the `[project]`, `[semantic_release]`, and `[options]` sections in `toml_dict`.

    Create a 'READMEMarkdownManager' instance to write out, if needed.
    """

    def __init__(
        self,
        toml_dict: TOMLDocumentIsh,
        root_path: Path,
        github_full_repo: str,
        token: str,
        gha_input: GHAInput,
    ):
        ffile = FromFiles(  # things requiring reading files
            root_path,
            gha_input,
        )
        gh_api = GitHubAPI(github_full_repo, oauth_token=token)
        self._validate_repo_initial_state(toml_dict)

        # [build-system]
        toml_dict["build-system"] = {
            "requires": ["setuptools>=78.1", "setuptools-scm"],
            "build-backend": "setuptools.build_meta",
        }

        # [project]
        # if we DON'T want PyPI stuff:
        if not gha_input.pypi_name:
            toml_dict["project"]["name"] = "_".join(ffile.packages).replace("_", "-")
            toml_dict["project"]["requires-python"] = gha_input.get_requires_python()
            # add the following if they were given:
            if gha_input.author or gha_input.author_email:
                toml_dict["project"]["authors"] = [{}]
                if gha_input.author:
                    toml_dict["project"]["authors"][0].update(
                        {"name": gha_input.author}
                    )
                if gha_input.author_email:
                    toml_dict["project"]["authors"][0].update(
                        {"email": gha_input.author_email}
                    )
            if gha_input.keywords:
                toml_dict["project"]["keywords"] = gha_input.keywords
        # if we DO want PyPI, then include everything:
        else:
            toml_dict["project"].update(
                {
                    "dynamic": ["version"],  # for 'setuptools-scm'
                    "name": gha_input.pypi_name,
                    "authors": [
                        {
                            "name": gha_input.author,
                            "email": gha_input.author_email,
                        }
                    ],
                    "description": gh_api.description,
                    "readme": ffile.readme_path.name,
                    "license": gha_input.license_spdx_id,
                    "license-files": (
                        [gha_input.license_file] if gha_input.license_file else []
                    ),
                    "keywords": gha_input.keywords,
                    "classifiers": gha_input.python_classifiers(),
                    "requires-python": gha_input.get_requires_python(),
                }
            )
            # [project.urls]
            toml_dict["project"]["urls"] = {
                "Homepage": f"https://pypi.org/project/{gha_input.pypi_name}/",
                "Tracker": f"{gh_api.url}/issues",
                "Source": gh_api.url,
            }

        # [tool]
        if not toml_dict.get("tool"):
            toml_dict["tool"] = {}

        # [tool.setuptools]
        if not toml_dict["tool"].get("setuptools"):
            toml_dict["tool"]["setuptools"] = {}
        toml_dict["tool"]["setuptools"].update(
            {
                "packages": {
                    "find": self._tool_setuptools_packages_find(gha_input),
                },
                "package-data": {
                    **toml_dict["tool"].get("setuptools", {}).get("package-data", {}),
                    "*": self._tool_setuptools_packagedata_star(toml_dict),
                },
            }
        )

        # [tool.setuptools_scm] -- an empty section is the bare minimum
        if not toml_dict["tool"].get("setuptools_scm"):
            toml_dict["tool"]["setuptools_scm"] = {}

        # [project.optional-dependencies][mypy]
        if gha_input.auto_mypy_option:
            try:
                toml_dict["project"]["optional-dependencies"]["mypy"] = sorted(
                    set(
                        itertools.chain.from_iterable(
                            deps
                            for opt, deps in toml_dict["project"][
                                "optional-dependencies"
                            ].items()
                            if opt != "mypy"
                        )
                    )
                )
            except KeyError:
                # there are no [project.optional-dependencies]
                # -> this is okay, it means that `WIPACrepo/wipac-dev-mypy-action` will
                #    just run w/ 'pip install .'
                pass

        # Automate some README stuff
        self.readme_mgr: READMEMarkdownManager | None
        if ffile.readme_path.suffix == ".md":
            self.readme_mgr = READMEMarkdownManager(
                ffile, github_full_repo, gha_input, gh_api
            )
        else:
            self.readme_mgr = None

    @staticmethod
    def _validate_repo_initial_state(toml_dict: TOMLDocumentIsh) -> None:
        # must *not* have these fields...
        if toml_dict.get("project", {}).get("version", None):
            raise Exception("pyproject.toml must NOT define 'project.version'")

        # must have these fields...
        # <none>

    @staticmethod
    def _tool_setuptools_packages_find(gha_input: GHAInput) -> dict[str, Any]:
        # only allow these...
        if gha_input.package_dirs:
            return {
                "include": gha_input.package_dirs
                + [f"{p}.*" for p in gha_input.package_dirs]
            }
        # disallow these...
        dicto: dict[str, Any] = {"namespaces": False}
        if gha_input.exclude_dirs:
            dicto.update({"exclude": gha_input.exclude_dirs})
        return dicto

    @staticmethod
    def _tool_setuptools_packagedata_star(toml_dict: TOMLDocumentIsh) -> list[str]:
        """Add py.typed to "*"."""
        try:
            current = set(toml_dict["tool"]["setuptools"]["package-data"]["*"])
        except KeyError:
            return ["py.typed"]

        if "py.typed" in current:
            return list(current)
        else:
            return list(current) + ["py.typed"]


def set_multiline_array(
    toml_dict: TOMLDocument,
    *path: str,
    sort: bool = False,
) -> None:
    """Convert the list at the given dotted path into a multiline TOML array."""
    cur = toml_dict
    for key in path[:-1]:
        cur = cur.get(key)  # type: ignore[assignment]
        if cur is None:
            return  # path doesn't exist
    last_key = path[-1]
    val = cur.get(last_key)
    if isinstance(val, list):
        if sort:
            cur[last_key] = array(sorted(val)).multiline(True)  # type: ignore[arg-type]
        else:
            cur[last_key] = array(val).multiline(True)  # type: ignore[arg-type]


def write_toml(
    toml_file: Path,
    github_full_repo: str,
    token: str,
    gha_input: GHAInput,
) -> READMEMarkdownManager | None:
    """Build/write the `pyproject.toml` sections according to `BUILDER_SECTION_NAME`.

    Return a 'READMEMarkdownManager' instance to write out. If, necessary.
    """
    toml_file = toml_file.resolve()
    if toml_file.exists():
        with open(toml_file, "r") as f:
            toml_dict = tomlkit.load(f)
    else:
        toml_dict = TOMLDocument()

    builder = PyProjectTomlBuilder(
        toml_dict,  # updates this
        toml_file.parent,
        github_full_repo,
        token,
        gha_input,
    )

    # make specific arrays multiline
    set_multiline_array(toml_dict, "project", "dependencies", sort=True)
    set_multiline_array(toml_dict, "project", "keywords")
    set_multiline_array(toml_dict, "project", "classifiers")
    optional_deps = toml_dict.get("project", {}).get("optional-dependencies", {})
    for key in optional_deps:
        set_multiline_array(optional_deps, key, sort=True)

    # remove sections that used to be auto-added but are now not needed
    # -> [tool.semantic_release], [tool.semantic_release.commit_parser_options]
    toml_dict["tool"].pop("semantic_release")

    # all done--write it!
    with open(toml_file, "w") as f:
        tomlkit.dump(toml_dict, f)

    return builder.readme_mgr


def work(
    toml_file: Path,
    github_full_repo: str,
    token: str,
    gha_input: GHAInput,
) -> None:
    """Build & write the pyproject.toml. Write the readme if necessary."""
    readme_mgr = write_toml(
        toml_file,
        github_full_repo,
        token,
        gha_input,
    )

    if readme_mgr:
        with open(readme_mgr.readme_path, "w") as f:
            for line in readme_mgr.lines:
                f.write(line)


def main() -> None:
    """Read and write all necessary files."""
    parser = argparse.ArgumentParser(
        description=f"Read/transform 'pyproject.toml' and 'README.md' files. "
        f"Builds out 'pyproject.toml' sections according to [{BUILDER_SECTION_NAME}].",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "--toml",
        type=lambda x: argparse_tools.validate_arg(
            Path(x),
            Path(x).name == "pyproject.toml",
            ValueError("toml file needs to be named 'pyproject.toml'"),
        ),
        required=True,
        help="path to the 'pyproject.toml' file",
    )
    parser.add_argument(
        "--github-full-repo",
        type=lambda x: argparse_tools.validate_arg(
            x,
            bool(re.match(r"(\w|-)+/(\w|-)+$", x)),
            ValueError("Not a valid GitHub repo"),
        ),
        required=True,
        help="Fully-named GitHub repo, ex: WIPACrepo/wipac-dev-tools",
    )
    parser.add_argument(
        "--token",
        required=True,
        help="An OAuth2 token, usually GITHUB_TOKEN",
    )

    def coerce_python_version(val: str | None) -> None | tuple[int, int]:
        if not val:
            return None
        # will raise error if not good format
        return tuple(int(d) for d in val.split(".", maxsplit=1))  # type: ignore[return-value]

    # From Client GitHub Action Input
    # REQUIRED
    parser.add_argument(
        "--python-min",
        # "3.12" -> (3,12)
        type=coerce_python_version,
        required=True,
        help="Minimum required Python version",
    )
    # OPTIONAL (python)
    parser.add_argument(
        "--python-max",
        # "3.12" -> (3,12)
        type=coerce_python_version,
        default=None,
        help="Maximum supported Python version. If not provided, the most recent Python version will be used.",
    )
    # OPTIONAL (packaging)
    parser.add_argument(
        "--package-dirs",
        nargs="*",
        type=str,
        default=[],
        help="List of directories to release. If not provided, all packages in the repository's root directory will be used.",
    )
    parser.add_argument(
        "--exclude-dirs",
        nargs="*",
        type=str,
        default=[],
        help="List of directories to exclude from release, relative to the repository's root directory.",
    )
    # OPTIONAL (releases)
    parser.add_argument(
        "--pypi-name",
        type=str,
        default="",
        help="Name of the PyPI package",
    )
    # OPTIONAL (meta)
    parser.add_argument(
        "--keywords",
        type=lambda x: [k.strip() for k in x.split(",")],
        default=[],
        help="keywords",
    )
    parser.add_argument(
        "--author",
        type=str,
        default="",
        help="Author of the package (required if the package is intended to be hosted on PyPI)",
    )
    parser.add_argument(
        "--author-email",
        type=str,
        default="",
        help="Email of the package author (required if the package is intended to be hosted on PyPI)",
    )
    parser.add_argument(
        "--license-spdx-id",
        type=str,
        default="",
        help="Repository's license SPDX ID",
    )
    parser.add_argument(
        "--license-file",
        type=str,
        default="",
        help="Repository's license file",
    )
    parser.add_argument(
        "--auto-mypy-option",
        type=strtobool,
        default=False,
        help="Whether to auto create/update the 'mypy' install option plus its dependencies",
    )
    args = parser.parse_args()
    logging_tools.set_level("DEBUG", LOGGER, use_coloredlogs=True)
    logging_tools.log_argparse_args(args, logger=LOGGER)

    gha_input = GHAInput(
        **{
            k: v
            for k, v in vars(args).items()
            # use arg if it has non-falsy value -- otherwise, rely on default
            if v and (k in [f.name for f in dataclasses.fields(GHAInput)])
        },
    )
    LOGGER.info(gha_input)

    work(
        args.toml,
        args.github_full_repo,
        args.token,
        gha_input,
    )


if __name__ == "__main__":
    main()
